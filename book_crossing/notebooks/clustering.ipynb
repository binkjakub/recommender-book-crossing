{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "MAIN_MODULE_PATH = os.path.join(os.getcwd(), '..', '..')\n",
    "sys.path.append(MAIN_MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightfm.data\n",
    "import lightfm.cross_validation\n",
    "import lightfm.evaluation\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, KFold, train_test_split\n",
    "from surprise.prediction_algorithms.co_clustering import CoClustering\n",
    "\n",
    "from defaults import BOOK_RATINGS, BOOKS, USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings(path=BOOK_RATINGS):\n",
    "    ratings = pd.read_csv(BOOK_RATINGS, sep=';')\n",
    "    ratings['Book-Rating'] = ratings['Book-Rating'].astype('int8')\n",
    "    return ratings\n",
    "\n",
    "def load_books(path=BOOKS):\n",
    "    books = pd.read_csv(path, sep=';', error_bad_lines=False, index_col='ISBN')    \n",
    "    books = books.loc[pd.to_numeric(books['Year-Of-Publication'], errors='coerce').dropna().index]\n",
    "    books['Year-Of-Publication'] = books['Year-Of-Publication'].astype(\"int8\")\n",
    "    return books\n",
    "\n",
    "def load_users(path=USERS):\n",
    "    return pd.read_csv(path, sep=';', index_col='User-ID')\n",
    "\n",
    "def _filter_ratings(ratings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Filters out interaction of user and books having #interactions below the threshold.\"\"\"\n",
    "    book_interactions_cutoff = user_interaction_cutoff = 10\n",
    "    book_mask = (ratings['ISBN'].map(ratings['ISBN'].value_counts())\n",
    "                 >= book_interactions_cutoff)\n",
    "    ratings = ratings[book_mask]\n",
    "\n",
    "    user_mask = (ratings['User-ID'].map(ratings['User-ID'].value_counts())\n",
    "                 >= user_interaction_cutoff)\n",
    "    ratings = ratings[user_mask]\n",
    "\n",
    "    # project ids to indices - make index-space compact\n",
    "    ratings['ISBN'] = ratings['ISBN'].astype('category').cat.codes\n",
    "    ratings['User-ID'] = ratings['User-ID'].astype('category').cat.codes\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, books, users = load_ratings(), load_books(), load_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = preprocess_ratings(ratings, books, users)[['ISBN', 'User-ID', 'Book-Rating']]\n",
    "ratings = _filter_ratings(ratings)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((float(est), float(true_r)))\n",
    "    \n",
    "    scores = []\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        pred, true = zip(*user_ratings)\n",
    "        true, pred = [list(true)], [list(pred)]\n",
    "        score = ndcg_score(true, pred, k=k)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(n_clusters_users, n_clusters_items, i):\n",
    "    algo = CoClustering(n_clusters_users, n_clusters_items)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=4)\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    return {'n_clusters_users': n_clusters_users, 'n_clusters_items': n_clusters_items, 'i': i, 'precision': precision, 'recall': recall, 'ndcg_at_k': ndcg_at_k(predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(ratings, Reader(rating_scale=(1, 10)))\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=RANDOM_STATE)\n",
    "\n",
    "n_clusters_users = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "n_clusters_items = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n",
    "i = [0, 1]\n",
    "\n",
    "with multiprocessing.Pool(processes=15) as pool:\n",
    "    results = pool.starmap(evaluate, tqdm(list(itertools.product(n_clusters_users, n_clusters_items, i))))\n",
    "        \n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = results[results.i ==0]\n",
    "to_plot = to_plot[~to_plot.duplicated()]\n",
    "to_plot = to_plot.pivot(\"n_clusters_users\", \"n_clusters_items\", \"precision\")\n",
    "sns.heatmap(to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = results[results.i == 0]\n",
    "to_plot = to_plot[~to_plot.duplicated()]\n",
    "to_plot = to_plot.pivot(\"n_clusters_users\", \"n_clusters_items\", \"recall\")\n",
    "sns.heatmap(to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = results[results.i ==0]\n",
    "to_plot = to_plot[~to_plot.duplicated()]\n",
    "to_plot = to_plot.pivot(\"n_clusters_users\", \"n_clusters_items\", \"ndcg_at_k\")\n",
    "sns.heatmap(to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='recall', ascending=False)[['precision','recall','ndcg_at_k']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='ndcg_at_k', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs",
   "language": "python",
   "name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
